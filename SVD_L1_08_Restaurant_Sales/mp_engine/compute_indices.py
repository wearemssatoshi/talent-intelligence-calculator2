#!/usr/bin/env python3
"""
KFâ‘  å¤šå±¤ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®—å‡ºã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å£²ä¸ŠCSVã‹ã‚‰ä»¥ä¸‹ã‚’çµ±è¨ˆçš„ã«ç®—å‡ºã—ã€mp_indices.json ã‚’æ›´æ–°ã™ã‚‹:
  - sekki_index:  24ç¯€æ°—åˆ¥ã®ç¹å¿™åº¦ (1.00-5.00)  æ‹ ç‚¹åˆ¥
  - weekly_index: ISOé€±ç•ªå·åˆ¥ã®ç¹å¿™åº¦ (1.00-5.00) æ‹ ç‚¹åˆ¥
  - daily_index:  ç¥æ—¥/ç‰¹åˆ¥æ—¥ã®ç¹å¿™åº¦å®šç¾©
"""

import csv
import json
import os
import sys
from datetime import date, datetime, timedelta
from collections import defaultdict

# â”€â”€ Paths â”€â”€
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
CSV_DIR = os.path.join(os.path.dirname(SCRIPT_DIR), "csv_output")
INDICES_PATH = os.path.join(SCRIPT_DIR, "mp_indices.json")
CONFIG_PATH = os.path.join(SCRIPT_DIR, "restaurant_config.json")

# â”€â”€ Import sekki engine for dateâ†’sekki mapping â”€â”€
sys.path.insert(0, SCRIPT_DIR)
from sekki import get_sekki, SEKKI_BOUNDARIES, WEEKDAY_JA


def load_config():
    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        return json.load(f)


def load_indices():
    with open(INDICES_PATH, "r", encoding="utf-8") as f:
        return json.load(f)


def load_csv_sales(csv_path, grand_total_col="grand_total"):
    """CSVã‚’èª­ã¿è¾¼ã¿ã€æ—¥ä»˜â†’å£²ä¸Šã®dictã‚’è¿”ã™"""
    records = []
    if not os.path.exists(csv_path):
        return records
    with open(csv_path, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            try:
                d = row["date"]
                sales = int(float(row.get(grand_total_col, 0) or 0))
                if sales > 0:
                    records.append({"date": d, "sales": sales})
            except (ValueError, KeyError):
                continue
    return records


def min_max_normalize(values, low=1.00, high=5.00):
    """min-maxæ­£è¦åŒ– â†’ low-high"""
    if not values:
        return []
    mn = min(values)
    mx = max(values)
    if mx == mn:
        mid = (low + high) / 2
        return [round(mid, 2) for _ in values]
    return [round(low + (v - mn) / (mx - mn) * (high - low), 2) for v in values]


def compute_sekki_index(records):
    """
    å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‹ã‚‰24ç¯€æ°—åˆ¥ã®å¹³å‡å£²ä¸Šã‚’ç®—å‡ºã—ã€1.00-5.00ã«æ­£è¦åŒ–
    Returns: {"ç™½éœ²": 4.85, "ç«‹ç§‹": 4.62, ...}
    """
    sekki_sales = defaultdict(list)  # ã‚»ãƒƒã‚­å â†’ [sales, sales, ...]

    for rec in records:
        d = datetime.strptime(rec["date"], "%Y-%m-%d").date()
        try:
            sekki_name, _, _, _ = get_sekki(d)
            sekki_sales[sekki_name].append(rec["sales"])
        except ValueError:
            continue

    # å„ç¯€æ°—ã®å¹³å‡å£²ä¸Šã‚’ç®—å‡º
    sekki_avg = {}
    for name, sales_list in sekki_sales.items():
        sekki_avg[name] = sum(sales_list) / len(sales_list)

    # å…¨24ç¯€æ°—ã‚’ã‚«ãƒãƒ¼ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒãªã„ç¯€æ°—ã¯æœ€ä½Žå€¤ã«ï¼‰
    all_sekki = [
        "å°å¯’", "å¤§å¯’", "ç«‹æ˜¥", "é›¨æ°´", "å•“èŸ„", "æ˜¥åˆ†",
        "æ¸…æ˜Ž", "ç©€é›¨", "ç«‹å¤", "å°æº€", "èŠ’ç¨®", "å¤è‡³",
        "å°æš‘", "å¤§æš‘", "ç«‹ç§‹", "å‡¦æš‘", "ç™½éœ²", "ç§‹åˆ†",
        "å¯’éœ²", "éœœé™", "ç«‹å†¬", "å°é›ª", "å¤§é›ª", "å†¬è‡³"
    ]

    avg_values = [sekki_avg.get(s, 0) for s in all_sekki]
    normalized = min_max_normalize(avg_values)

    result = {}
    for i, name in enumerate(all_sekki):
        result[name] = normalized[i]

    return result


def compute_weekly_index(records):
    """
    å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ISOé€±ç•ªå·åˆ¥ã®å¹³å‡å£²ä¸Šã‚’ç®—å‡ºã—ã€1.00-5.00ã«æ­£è¦åŒ–
    Returns: {"1": 2.35, "2": 2.48, ..., "52": 3.12}
    """
    weekly_sales = defaultdict(list)

    for rec in records:
        d = datetime.strptime(rec["date"], "%Y-%m-%d").date()
        iso_week = d.isocalendar()[1]
        # ISOé€±53ã¯52ã«çµ±åˆ
        if iso_week > 52:
            iso_week = 52
        weekly_sales[iso_week].append(rec["sales"])

    # å„é€±ã®å¹³å‡å£²ä¸Š
    weekly_avg = {}
    for week, sales_list in weekly_sales.items():
        weekly_avg[week] = sum(sales_list) / len(sales_list)

    # 52é€±ã‚’ã‚«ãƒãƒ¼
    avg_values = [weekly_avg.get(w, 0) for w in range(1, 53)]
    normalized = min_max_normalize(avg_values)

    result = {}
    for i, w in enumerate(range(1, 53)):
        result[str(w)] = normalized[i]

    return result


def compute_daily_index():
    """
    ç¥æ—¥ãƒ»ç‰¹åˆ¥æ—¥ã®å®šç¾©ï¼ˆé™çš„ãƒ‡ãƒ¼ã‚¿ + æ±Žç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
    Returns: dict of special day definitions
    """
    # æ—¥æœ¬ã®ç¥æ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ—¥ä»˜å›ºå®šã®ã‚‚ã®ï¼‰
    fixed_holidays = {
        "01-01": {"name": "å…ƒæ—¥", "pt": 4.50},
        "01-02": {"name": "æ­£æœˆ2æ—¥", "pt": 4.00},
        "01-03": {"name": "æ­£æœˆ3æ—¥", "pt": 4.00},
        "02-11": {"name": "å»ºå›½è¨˜å¿µã®æ—¥", "pt": 3.50},
        "02-23": {"name": "å¤©çš‡èª•ç”Ÿæ—¥", "pt": 3.50},
        "03-21": {"name": "æ˜¥åˆ†ã®æ—¥(å‰å¾Œ)", "pt": 3.00},
        "04-29": {"name": "æ˜­å’Œã®æ—¥", "pt": 4.00},
        "04-30": {"name": "GWä¸­æ—¥", "pt": 4.50},
        "05-01": {"name": "GWä¸­æ—¥", "pt": 4.50},
        "05-02": {"name": "GWä¸­æ—¥", "pt": 4.50},
        "05-03": {"name": "æ†²æ³•è¨˜å¿µæ—¥", "pt": 5.00},
        "05-04": {"name": "ã¿ã©ã‚Šã®æ—¥", "pt": 5.00},
        "05-05": {"name": "ã“ã©ã‚‚ã®æ—¥", "pt": 5.00},
        "05-06": {"name": "GWæŒ¯æ›¿", "pt": 4.50},
        "07-20": {"name": "æµ·ã®æ—¥(å‰å¾Œ)", "pt": 3.50},
        "08-11": {"name": "å±±ã®æ—¥", "pt": 4.00},
        "08-12": {"name": "ãŠç›†å‰", "pt": 4.50},
        "08-13": {"name": "ãŠç›†", "pt": 5.00},
        "08-14": {"name": "ãŠç›†", "pt": 5.00},
        "08-15": {"name": "ãŠç›†", "pt": 5.00},
        "08-16": {"name": "ãŠç›†æ˜Žã‘", "pt": 4.00},
        "09-15": {"name": "æ•¬è€ã®æ—¥(å‰å¾Œ)", "pt": 3.50},
        "09-23": {"name": "ç§‹åˆ†ã®æ—¥(å‰å¾Œ)", "pt": 3.50},
        "10-14": {"name": "ã‚¹ãƒãƒ¼ãƒ„ã®æ—¥(å‰å¾Œ)", "pt": 3.50},
        "11-03": {"name": "æ–‡åŒ–ã®æ—¥", "pt": 3.50},
        "11-23": {"name": "å‹¤åŠ´æ„Ÿè¬ã®æ—¥", "pt": 3.50},
        "12-23": {"name": "ã‚¯ãƒªã‚¹ãƒžã‚¹ã‚¤ãƒ–å‰æ—¥", "pt": 4.00},
        "12-24": {"name": "ã‚¯ãƒªã‚¹ãƒžã‚¹ã‚¤ãƒ–", "pt": 5.00},
        "12-25": {"name": "ã‚¯ãƒªã‚¹ãƒžã‚¹", "pt": 5.00},
        "12-29": {"name": "å¹´æœ«", "pt": 3.50},
        "12-30": {"name": "å¹´æœ«", "pt": 4.00},
        "12-31": {"name": "å¤§æ™¦æ—¥", "pt": 4.50},
    }

    # æœ­å¹Œç‰¹æœ‰ã‚¤ãƒ™ãƒ³ãƒˆ
    sapporo_events = {
        "02-04": {"name": "é›ªã¾ã¤ã‚Š(å‰å¾Œ)", "pt": 4.50},
        "02-05": {"name": "é›ªã¾ã¤ã‚Š", "pt": 5.00},
        "02-06": {"name": "é›ªã¾ã¤ã‚Š", "pt": 5.00},
        "02-07": {"name": "é›ªã¾ã¤ã‚Š", "pt": 5.00},
        "02-08": {"name": "é›ªã¾ã¤ã‚Š", "pt": 5.00},
        "02-09": {"name": "é›ªã¾ã¤ã‚Š", "pt": 5.00},
        "02-10": {"name": "é›ªã¾ã¤ã‚Š", "pt": 5.00},
        "02-11": {"name": "é›ªã¾ã¤ã‚Š(æœ€çµ‚æ—¥)", "pt": 4.50},
        "06-14": {"name": "åŒ—æµ·é“ç¥žå®®ä¾‹ç¥­(å‰å¾Œ)", "pt": 4.00},
        "06-15": {"name": "åŒ—æµ·é“ç¥žå®®ä¾‹ç¥­", "pt": 4.50},
        "06-16": {"name": "åŒ—æµ·é“ç¥žå®®ä¾‹ç¥­", "pt": 4.50},
        "09-06": {"name": "ã‚ªãƒ¼ã‚¿ãƒ ãƒ•ã‚§ã‚¹ãƒˆ(å‰å¾Œ)", "pt": 4.50},
        "09-07": {"name": "ã‚ªãƒ¼ã‚¿ãƒ ãƒ•ã‚§ã‚¹ãƒˆ", "pt": 5.00},
        "09-28": {"name": "ã‚ªãƒ¼ã‚¿ãƒ ãƒ•ã‚§ã‚¹ãƒˆ(æœ€çµ‚)", "pt": 4.50},
        "11-22": {"name": "ãƒ›ãƒ¯ã‚¤ãƒˆã‚¤ãƒ«ãƒŸé–‹å§‹(å‰å¾Œ)", "pt": 3.50},
    }

    # é€£ä¼‘ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ›œæ—¥ä¾å­˜ â€” å‹•çš„åˆ¤å®šç”¨ï¼‰
    holiday_patterns = {
        "golden_week": {"name": "GW", "months": [4, 5], "days": list(range(29, 32)) + list(range(1, 7)), "pt": 4.50},
        "obon": {"name": "ãŠç›†", "months": [8], "days": list(range(11, 17)), "pt": 4.50},
        "yearend": {"name": "å¹´æœ«å¹´å§‹", "months": [12, 1], "days": list(range(28, 32)) + list(range(1, 4)), "pt": 4.00},
    }

    return {
        "fixed_holidays": fixed_holidays,
        "sapporo_events": sapporo_events,
        "holiday_patterns": holiday_patterns,
    }


def get_base_store_mapping(config):
    """æ‹ ç‚¹ID â†’ {store_ids, csv_files, grand_total_cols}"""
    mapping = {}
    for base in config["bases"]:
        base_id = base["id"]
        stores = []
        for store in base["stores"]:
            csv_path = os.path.join(CSV_DIR, store["csv_file"])
            gt_col = store.get("grand_total_col", "grand_total")
            # Exclude channels if specified
            exclude = store.get("exclude_channels_from_kf", [])
            stores.append({
                "id": store["id"],
                "csv_file": csv_path,
                "gt_col": gt_col,
                "exclude": exclude,
            })
        mapping[base_id] = stores
    return mapping


def compute_base_aggregated_sales(stores_info):
    """
    æ‹ ç‚¹å†…ã®å…¨åº—èˆ—ã®å£²ä¸Šã‚’çµ±åˆ
    (ãŸã ã—ã€BEERGARDENã®ã‚ˆã†ãªé™¤å¤–ãƒãƒ£ãƒãƒ«ã¯è€ƒæ…®ã—ãªã„ â€” grand_totalã‚’ä½¿ç”¨)
    Returns: [{date, sales}, ...]
    """
    date_sales = defaultdict(int)

    for store in stores_info:
        records = load_csv_sales(store["csv_file"], store["gt_col"])
        for rec in records:
            date_sales[rec["date"]] += rec["sales"]

    return [{"date": d, "sales": s} for d, s in sorted(date_sales.items()) if s > 0]


def main():
    print("=" * 70)
    print("KFâ‘  å¤šå±¤ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®—å‡ºã‚¨ãƒ³ã‚¸ãƒ³")
    print("=" * 70)

    config = load_config()
    indices = load_indices()
    base_mapping = get_base_store_mapping(config)

    # â”€â”€ 1. ç¯€æ°—åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆæ‹ ç‚¹ã”ã¨ï¼‰â”€â”€
    print("\nðŸŒ¸ ç¯€æ°—åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®—å‡º...")
    sekki_indices = {}
    for base_id, stores in base_mapping.items():
        records = compute_base_aggregated_sales(stores)
        sekki_idx = compute_sekki_index(records)
        sekki_indices[base_id] = sekki_idx
        print(f"  âœ… {base_id}: {len(records)}æ—¥åˆ† â†’ 24ç¯€æ°—ã«ãƒžãƒƒãƒ”ãƒ³ã‚°")

        # TOP 5 / BOTTOM 5
        sorted_sekki = sorted(sekki_idx.items(), key=lambda x: x[1], reverse=True)
        print(f"     TOP: {', '.join(f'{s}={v:.2f}' for s, v in sorted_sekki[:3])}")
        print(f"     LOW: {', '.join(f'{s}={v:.2f}' for s, v in sorted_sekki[-3:])}")

    # â”€â”€ 2. é€±åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆæ‹ ç‚¹ã”ã¨ï¼‰â”€â”€
    print("\nðŸ“… é€±åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®—å‡º...")
    weekly_indices = {}
    for base_id, stores in base_mapping.items():
        records = compute_base_aggregated_sales(stores)
        weekly_idx = compute_weekly_index(records)
        weekly_indices[base_id] = weekly_idx
        print(f"  âœ… {base_id}: 52é€±ã«ãƒžãƒƒãƒ”ãƒ³ã‚°")

        # TOP 3 / BOTTOM 3
        sorted_weekly = sorted(weekly_idx.items(), key=lambda x: x[1], reverse=True)
        print(f"     TOP: {', '.join(f'W{w}={v:.2f}' for w, v in sorted_weekly[:3])}")
        print(f"     LOW: {', '.join(f'W{w}={v:.2f}' for w, v in sorted_weekly[-3:])}")

    # â”€â”€ 3. æ—¥åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ â”€â”€
    print("\nðŸŽŒ æ—¥åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®šç¾©...")
    daily_index = compute_daily_index()
    print(f"  âœ… å›ºå®šç¥æ—¥: {len(daily_index['fixed_holidays'])}ä»¶")
    print(f"  âœ… æœ­å¹Œã‚¤ãƒ™ãƒ³ãƒˆ: {len(daily_index['sapporo_events'])}ä»¶")
    print(f"  âœ… é€£ä¼‘ãƒ‘ã‚¿ãƒ¼ãƒ³: {len(daily_index['holiday_patterns'])}ä»¶")

    # â”€â”€ 4. mp_indices.json ã«æ›¸ãè¾¼ã¿ â”€â”€
    print("\nðŸ’¾ mp_indices.json æ›´æ–°ä¸­...")

    # æ‹ ç‚¹ã”ã¨ã« sekki_index ã¨ weekly_index ã‚’è¿½åŠ 
    for base_id in base_mapping:
        if base_id in indices["bases"]:
            indices["bases"][base_id]["sekki_index"] = sekki_indices[base_id]
            indices["bases"][base_id]["weekly_index"] = weekly_indices[base_id]

    # daily_index ã‚’ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã«è¿½åŠ 
    indices["daily_index"] = daily_index

    # sekki_24_levels ã®ã‚·ãƒ¼ã‚ºãƒ³å¸¯ã¯ç¶­æŒï¼ˆå‚ç…§ç”¨ï¼‰
    # ãŸã ã— season_pt ã‚’å‡ç­‰é…åˆ†ã«æ›´æ–°
    levels = indices["sekki_24_levels"]["levels"]
    sorted_levels = sorted(levels.items(), key=lambda x: x[1]["rank"])
    step = 4.00 / 23  # 5.00 â†’ 1.00 ã‚’23ã‚¹ãƒ†ãƒƒãƒ—
    for i, (name, info) in enumerate(sorted_levels):
        new_pt = round(5.00 - i * step, 2)
        levels[name]["season_pt"] = new_pt

    # ãƒ¡ã‚¿æ›´æ–°
    indices["_meta"]["last_updated"] = datetime.now().strftime("%Y-%m-%d")
    indices["_meta"]["description"] = "Momentum Peaks æ‹ ç‚¹å®šæŒ‡æ•° â€” 5å±¤ç’°å¢ƒå®šæ•°ï¼ˆæœˆåˆ¥/æ›œæ—¥åˆ¥/ç¯€æ°—åˆ¥/é€±åˆ¥/æ—¥åˆ¥ï¼‰"

    with open(INDICES_PATH, "w", encoding="utf-8") as f:
        json.dump(indices, f, ensure_ascii=False, indent=4)

    print("  âœ… mp_indices.json æ›´æ–°å®Œäº†")

    # â”€â”€ ã‚µãƒžãƒªãƒ¼å‡ºåŠ› â”€â”€
    print("\n" + "=" * 70)
    print("âœ… å¤šå±¤ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®—å‡ºå®Œäº†")
    print("=" * 70)
    print(f"  æ‹ ç‚¹æ•°: {len(base_mapping)}")
    print(f"  ç¯€æ°—åˆ¥: 24åŒºåˆ† Ã— {len(base_mapping)}æ‹ ç‚¹")
    print(f"  é€±åˆ¥:   52åŒºåˆ† Ã— {len(base_mapping)}æ‹ ç‚¹")
    print(f"  æ—¥åˆ¥:   {len(daily_index['fixed_holidays']) + len(daily_index['sapporo_events'])}ç‰¹åˆ¥æ—¥")
    print()

    # ã‚·ãƒ¼ã‚ºãƒ³å¸¯ã‚µãƒžãƒªãƒ¼
    print("ðŸ“Š ã‚·ãƒ¼ã‚ºãƒ³å¸¯ (ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹):")
    for name, info in sorted_levels:
        print(f"  #{info['rank']:>2} {name} â†’ {info['season']:>12} {info['season_pt']:.2f}")


if __name__ == "__main__":
    main()
