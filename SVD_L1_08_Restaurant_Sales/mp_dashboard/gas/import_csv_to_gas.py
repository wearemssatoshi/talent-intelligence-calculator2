#!/usr/bin/env python3
"""
MP CSV â†’ GAS Import Script (v3 â€” F/Bå®Œå…¨åˆ†è§£ç‰ˆ)
================================================
å…¨ãƒãƒ£ãƒãƒ«ã®Food/Drinkåˆ†è§£ã‚’å«ã‚€å®Œå…¨ç‰ˆã€‚
å„åº—èˆ—CSVã‹ã‚‰ãƒ•ãƒ©ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿è¡Œã‚’æŠ½å‡ºã—ã€GAS APIã«POSTã™ã‚‹ã€‚

Usage:
  python3 import_csv_to_gas.py --url YOUR_GAS_DEPLOY_URL
  python3 import_csv_to_gas.py --url YOUR_GAS_DEPLOY_URL --store MOIWA_JW
  python3 import_csv_to_gas.py --url YOUR_GAS_DEPLOY_URL --setup
  python3 import_csv_to_gas.py --url YOUR_GAS_DEPLOY_URL --dry-run
"""

import csv
import json
import sys
import os
import urllib.request
import urllib.error

# â”€â”€ ãƒ‘ã‚¹è¨­å®š â”€â”€
CSV_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', '..', 'csv_output')

# â”€â”€ å®‰å…¨ãªintå¤‰æ› â”€â”€
def i(row, key):
    val = row.get(key, '')
    if val == '' or val is None:
        return 0
    try:
        return int(float(val))
    except (ValueError, TypeError):
        return 0

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# åº—èˆ—åˆ¥ã‚·ãƒ¼ãƒˆå®šç¾© â€” F/Bå®Œå…¨åˆ†è§£ç‰ˆ
# ãƒ˜ãƒƒãƒ€ãƒ¼é †åºã¯Code.gsã®STORE_SHEETSã¨å®Œå…¨ä¸€è‡´ã•ã›ã‚‹ã“ã¨
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STORE_SHEETS = {
    # MOIWA_JW: date|L_Food|L_Drink|Läººæ•°|D_Food|D_Drink|Däººæ•°|TO_Food|TO_Drink|å¸­æ–™|å—äº¬éŒ |èŠ±æŸ|ç‰©è²©_é£Ÿå“|ç‰©è²©_ã‚¢ãƒ‘ãƒ¬ãƒ«
    'MOIWA_JW': {
        'csv_file': 'JW_daily.csv',
        'mapper': lambda r: [
            r.get('date', ''),
            i(r, 'l_food'), i(r, 'l_drink'), i(r, 'l_count'),
            i(r, 'd_food'), i(r, 'd_drink'), i(r, 'd_count'),
            i(r, 'to_food'), i(r, 'to_drink'),
            i(r, 'seat_fee'),
            i(r, 'lock_fee'),
            i(r, 'flower'),
            i(r, 'curry'),   # ç‰©è²©_é£Ÿå“: ã‚‚ãƒ¼ã‚Šã™ã‚«ãƒ¬ãƒ¼
            0,                # ç‰©è²©_ã‚¢ãƒ‘ãƒ¬ãƒ«: ãªã—
        ]
    },
    # TVTOWER_GA: date|L_Food|L_Drink|Läººæ•°|D_Food|D_Drink|Däººæ•°|TO_Food|TO_Drink|å®´ä¼š_Food|å®´ä¼š_Drink|å®´ä¼šäººæ•°|å®¤æ–™|å±•æœ›å°|ç‰©è²©_é£Ÿå“|ç‰©è²©_ã‚¢ãƒ‘ãƒ¬ãƒ«
    'TVTOWER_GA': {
        'csv_file': 'GA_daily.csv',
        'mapper': lambda r: [
            r.get('date', ''),
            i(r, 'l_food'), i(r, 'l_drink'), i(r, 'l_count'),
            i(r, 'd_food'), i(r, 'd_drink'), i(r, 'd_count'),
            i(r, 'to_food'), i(r, 'to_drink'),
            i(r, 'bq_food'), i(r, 'bq_drink'), i(r, 'bq_count'),
            i(r, 'room_fee'),
            0,                # å±•æœ›å°ï¼ˆCSVã«åˆ—ãªã—ï¼‰
            0, 0,             # ç‰©è²©
        ]
    },
    # TVTOWER_BG: date|Food|Drink|Tent|äººæ•°|ç‰©è²©_é£Ÿå“|ç‰©è²©_ã‚¢ãƒ‘ãƒ¬ãƒ«
    'TVTOWER_BG': {
        'csv_file': 'GA_daily.csv',
        'mapper': lambda r: [
            r.get('date', ''),
            i(r, 'bg_food'),
            i(r, 'bg_drink'),
            i(r, 'bg_tent'),
            i(r, 'bg_count'),
            0,                # ç‰©è²©_é£Ÿå“
            i(r, 'bg_goods'), # ç‰©è²©_ã‚¢ãƒ‘ãƒ¬ãƒ«: Tã‚·ãƒ£ãƒ„ç­‰
        ],
        'filter': lambda r: i(r, 'bg_total') > 0
    },
    # OKURAYAMA_NP: date|L_Food|L_Drink|Läººæ•°|D_Food|D_Drink|Däººæ•°|å®¤æ–™|èŠ±æŸ|Event_Food|Event_Drink|Eventäººæ•°|ç‰©è²©_é£Ÿå“|ç‰©è²©_ã‚¢ãƒ‘ãƒ¬ãƒ«
    'OKURAYAMA_NP': {
        'csv_file': 'NP_daily.csv',
        'mapper': lambda r: [
            r.get('date', ''),
            i(r, 'l_food'), i(r, 'l_drink'), i(r, 'l_count'),
            i(r, 'd_food'), i(r, 'd_drink'), i(r, 'd_count'),
            i(r, 'l_room_fee') + i(r, 'd_room_fee') + i(r, 'event_room_fee'),  # å®¤æ–™ã¾ã¨ã‚
            i(r, 'l_flower') + i(r, 'd_flower') + i(r, 'event_flower'),         # èŠ±æŸã¾ã¨ã‚
            i(r, 'event_food'), i(r, 'event_drink'), i(r, 'event_count'),
            0, 0,             # ç‰©è²©
        ]
    },
    # OKURAYAMA_Ce: date|Food|Drink|äººæ•°|ç‰©è²©_é£Ÿå“|ç‰©è²©_ã‚¢ãƒ‘ãƒ¬ãƒ«
    'OKURAYAMA_Ce': {
        'csv_file': 'Ce_daily.csv',
        'mapper': lambda r: [
            r.get('date', ''),
            i(r, 'food'),
            i(r, 'drink'),
            i(r, 'count'),
            0,                # ç‰©è²©_é£Ÿå“
            i(r, 'goods'),    # ç‰©è²©_ã‚¢ãƒ‘ãƒ¬ãƒ«
        ]
    },
    # OKURAYAMA_RP: date|Food|Drink|äººæ•°|ç‰©è²©_é£Ÿå“|ç‰©è²©_ã‚¢ãƒ‘ãƒ¬ãƒ«
    'OKURAYAMA_RP': {
        'csv_file': 'RP_daily.csv',
        'mapper': lambda r: [
            r.get('date', ''),
            i(r, 'food'),
            i(r, 'drink'),
            i(r, 'count'),
            0,                # ç‰©è²©_é£Ÿå“
            i(r, 'goods'),    # ç‰©è²©_ã‚¢ãƒ‘ãƒ¬ãƒ«
        ]
    },
    # AKARENGA_BQ: date|L_Food|L_Drink|Läººæ•°|AT_Food|AT_Drink|ATäººæ•°|D_Food|D_Drink|Däººæ•°|å¸­æ–™|ç‰©è²©_é£Ÿå“|ç‰©è²©_ã‚¢ãƒ‘ãƒ¬ãƒ«
    'AKARENGA_BQ': {
        'csv_file': 'BQ_daily.csv',
        'mapper': lambda r: [
            r.get('date', ''),
            i(r, 'l_food'), i(r, 'l_drink'), i(r, 'l_count'),
            i(r, 'at_food'), i(r, 'at_drink'), i(r, 'at_count'),
            i(r, 'd_food'), i(r, 'd_drink'), i(r, 'd_count'),
            i(r, 'seat_fee'),
            0, 0,             # ç‰©è²©
        ]
    },
    # AKARENGA_RYB: date|Food|Drink|äººæ•°|ç‰©è²©_é£Ÿå“|ç‰©è²©_ã‚¢ãƒ‘ãƒ¬ãƒ«
    'AKARENGA_RYB': {
        'csv_file': 'BQ_daily.csv',
        'mapper': lambda r: [
            r.get('date', ''),
            i(r, 'ryb_food'),
            i(r, 'ryb_drink'),
            i(r, 'ryb_count'),
            0, 0,             # ç‰©è²©
        ],
        'filter': lambda r: i(r, 'ryb_total') > 0
    },
}


def load_csv(sheet_name, config):
    """CSVã‹ã‚‰ãƒ•ãƒ©ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿è¡Œã‚’ç”Ÿæˆ"""
    csv_path = os.path.join(CSV_DIR, config['csv_file'])
    if not os.path.exists(csv_path):
        print(f'  âš  {csv_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
        return []

    records = []
    with open(csv_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            if not row.get('date', '').strip():
                continue
            if 'filter' in config and not config['filter'](row):
                continue
            try:
                mapped = config['mapper'](row)
                records.append(mapped)
            except Exception as e:
                print(f'  âš  ãƒãƒƒãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ ({row.get("date", "?")}): {e}')

    records.sort(key=lambda r: r[0])
    return records


def post_to_gas(url, action, payload):
    """GAS APIã«POST"""
    payload['action'] = action
    data = json.dumps(payload).encode('utf-8')

    req = urllib.request.Request(
        url,
        data=data,
        headers={'Content-Type': 'application/json'},
        method='POST'
    )

    try:
        with urllib.request.urlopen(req, timeout=300) as resp:
            result = json.loads(resp.read().decode())
            return result
    except urllib.error.HTTPError as e:
        body = e.read().decode() if e.fp else ''
        print(f'  âŒ HTTP {e.code}: {body[:200]}')
        return {'status': 'error', 'message': f'HTTP {e.code}'}
    except Exception as e:
        print(f'  âŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}')
        return {'status': 'error', 'message': str(e)}


def main():
    import argparse
    parser = argparse.ArgumentParser(description='MP CSV â†’ GAS Import v3')
    parser.add_argument('--url', required=True, help='GAS deploy URL')
    parser.add_argument('--store', help='ç‰¹å®šã‚·ãƒ¼ãƒˆã®ã¿ (ä¾‹: MOIWA_JW)')
    parser.add_argument('--setup', action='store_true', help='ã‚·ãƒ¼ãƒˆåˆæœŸä½œæˆã®ã¿')
    parser.add_argument('--dry-run', action='store_true', help='ãƒ‡ãƒ¼ã‚¿æ•°ã®ç¢ºèªã®ã¿')
    args = parser.parse_args()

    print('â•' * 60)
    print('MOMENTUM PEAKS â€” CSV â†’ GAS Import v3 (F/Bå®Œå…¨åˆ†è§£ç‰ˆ)')
    print(f'Target: {args.url[:60]}...')
    print('â•' * 60)

    if args.setup:
        print('\nğŸ“‹ ã‚·ãƒ¼ãƒˆåˆæœŸä½œæˆä¸­...')
        result = post_to_gas(args.url, 'setupSheets', {})
        if result.get('status') == 'ok':
            print(f'  âœ… ä½œæˆæ¸ˆã¿ã‚·ãƒ¼ãƒˆ: {result.get("created", [])}')
            print(f'  ğŸ“Š åˆè¨ˆ {result.get("total_sheets", 0)} ã‚·ãƒ¼ãƒˆ')
        else:
            print(f'  âŒ ã‚¨ãƒ©ãƒ¼: {result.get("message")}')
        return

    stores = {args.store: STORE_SHEETS[args.store]} if args.store else STORE_SHEETS
    grand_total = 0

    for sheet_name, config in stores.items():
        print(f'\nğŸ“‚ {sheet_name} ({config["csv_file"]}) ...')
        rows = load_csv(sheet_name, config)
        print(f'   {len(rows)} è¡Œã‚’ãƒ­ãƒ¼ãƒ‰')

        if not rows:
            continue

        if args.dry_run:
            # ã‚µãƒ³ãƒ—ãƒ«è¡Œè¡¨ç¤º
            sample = rows[0]
            print(f'   [DRY RUN] {len(rows)} è¡Œã‚’æŠ•å…¥äºˆå®š')
            print(f'   ã‚µãƒ³ãƒ—ãƒ«: {sample[:5]}...')
            grand_total += len(rows)
            continue

        BATCH_SIZE = 500
        for start in range(0, len(rows), BATCH_SIZE):
            batch = rows[start:start + BATCH_SIZE]
            print(f'   ğŸ“¤ ãƒãƒƒãƒ {start+1}-{start+len(batch)} / {len(rows)} ...')
            result = post_to_gas(args.url, 'import', {
                'sheet': sheet_name,
                'rows': batch,
                'user': 'CSV_IMPORT_v3'
            })
            if result.get('status') == 'ok':
                imported = result.get('imported', 0)
                grand_total += imported
                print(f'   âœ… {imported} è¡Œã‚’æ›¸ãè¾¼ã¿')
            else:
                print(f'   âŒ ã‚¨ãƒ©ãƒ¼: {result.get("message")}')
                break

    print(f'\n{"â•" * 60}')
    print(f'åˆè¨ˆ: {grand_total} è¡Œ / {len(stores)} ã‚·ãƒ¼ãƒˆ')
    print('â•' * 60)


if __name__ == '__main__':
    main()
